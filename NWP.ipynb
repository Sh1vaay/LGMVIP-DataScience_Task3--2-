{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50dc76f6",
   "metadata": {},
   "source": [
    "# 03 ADVANCED LEVEL TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216630bc",
   "metadata": {},
   "source": [
    "###  2)Next Word Prediction: Using Tensorflow and Keras library train a RNN, to predict the next word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562bd261",
   "metadata": {},
   "source": [
    "## Abhishek_Sutar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a47a88",
   "metadata": {},
   "source": [
    "### import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fa0b8",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d361d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = open('dataset.txt',encoding='utf8').read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588037ab",
   "metadata": {},
   "source": [
    "### split the dataset into each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b522e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tknz = RegexpTokenizer(r'\\w+')\n",
    "words = tknz.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(words)\n",
    "unique_word_index = dict((c, i) for i, c in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05848d",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f722f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_len = 8\n",
    "prev_w = []\n",
    "next_w = []\n",
    "for i in range(len(words) - w_len):\n",
    "    prev_w.append(words[i:i + w_len])\n",
    "    next_w.append(words[i + w_len])\n",
    "print(prev_w[0])\n",
    "print(next_w[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15695484",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(prev_w), w_len, len(unique_words)), dtype=bool)\n",
    "Y = np.zeros((len(next_w), len(unique_words)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ef2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a873965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, each_words in enumerate(prev_w):\n",
    "    for j, each_word in enumerate(each_words):\n",
    "        X[i, j, unique_word_index[each_word]] = 1\n",
    "    Y[i, unique_word_index[next_w[i]]] = 1\n",
    "print(X[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab940f0",
   "metadata": {},
   "source": [
    "###  Recurrent Neural networks for next word prediction model.LSTM model, which is a very powerful RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(w_len, len(unique_words))))\n",
    "model.add(Dense(len(unique_words)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c019a",
   "metadata": {},
   "source": [
    "### Training the Next Word Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f987910a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, Y, validation_split=0.05, batch_size=128, epochs=7, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_wp.h5')\n",
    "pickle.dump(his tory, open(\"history.p\", \"wb\"))\n",
    "model = load_model('model_wp.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe41f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, w_len, len(unique_words)))\n",
    "    for t, word in enumerate(text.split()):\n",
    "        x[0, t, unique_word_index[word]] = 1        \n",
    "    return x\n",
    "\n",
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
    "\n",
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char      \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion\n",
    "\n",
    "def pred_w(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [unique_words[idx] for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5efa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines=[\"It is the quality of one’s convictions that determines success, not the number of followers —Remus Lupin\",\n",
    "\"I’m going to keep going until I succeed—or I die. Don’t think I don’t know how this might end. I’ve known it for years. — Harry Potter\"\n",
    ",\"That  more trouble than it’s worth. And quite honestly, I’ve had enough trouble for a lifetime.— Harry Potter\"\n",
    ",\"We’re all human, are not we? Every human life is worth the same, and worth saving. Kingsley Shacklebolt\"\n",
    ",\"‘Does it hurt?’ The childish question had escaped Harry's lips before he could stop it. ‘Dying? Not at all,’ said Sirius. ‘Quicker and easier than falling asleep.’\"\n",
    ",\"He can run faster than Severus Snape confronted with shampoo.— Fred Weasley\"\n",
    "\n",
    ",\"Words are, in my not-so-humble opinion, our most inexhaustible source of magic. Capable of both inflicting injury, and remedying it. ― Albus Dumbledore\"\n",
    ",\"Not my daughter, you b*tch! ― Molly Weasley\"\n",
    ",\"And Percy was shaking his brother, and Ron was kneeling beside them, and Fred's eyes stared without seeing, the ghost of his last laugh still etched upon his face.\"\n",
    ",\"It is a curious thing, Harry, but perhaps those who are best suited to power are those who have never sought it. Those who, like you, have leadership thrust upon them, and take up the mantle because they must, and find to their own surprise that they wear it well. — Albus Dumbledore\"\n",
    ",\"I've always wanted to use that spell. ― Minerva McGonagall\"\n",
    ",\"Of course it is happening inside your head, Harry, but why on earth should that mean that it is not real? ― Albus Dumbledore\"\n",
    ",\"Do not pity the dead, Harry. Pity the living, and, above all, those who live without love. ― Albus Dumbledore\"\n",
    ",\"‘Why are they all staring?’ demanded Albus as he and Rose craned around to look at the other students. ‘Don’t let it worry you,’ said Ron. ‘It’s me. I’m extremely famous.’\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae81ce8",
   "metadata": {},
   "source": [
    "### Testing Next Word Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in lines:\n",
    "    print(\"original Sentence:\" ,l,end='')\n",
    "    seq = \" \".join(tknz.tokenize(l.lower())[0:5])\n",
    "    print(\"\\nSequence:\",seq)\n",
    "    print(\"Next possible words:\",pred_w(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618e9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053853aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
